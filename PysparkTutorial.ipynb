{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f3b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f696bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45923a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pysprak\n"
     ]
    }
   ],
   "source": [
    "print(\"hello pysprak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af659043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krishna</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudanshu</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vedant</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Age\n",
       "0   Krishna  450\n",
       "1  Sudanshu   30\n",
       "2      Mike   33\n",
       "3    Vedant  100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('testexcel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1b81d",
   "metadata": {},
   "source": [
    "#PYSPARK SESSION BEGINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e863e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7acf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8544892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-E1PBNIN:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15cfe24af10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89585a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|     _c0|_c1|\n",
      "+--------+---+\n",
      "|    Name|Age|\n",
      "| Krishna|450|\n",
      "|Sudanshu| 30|\n",
      "|    Mike| 33|\n",
      "|  Vedant|100|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv('testexcel.csv').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63bfcce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_data=spark.read.option('header','true').csv('testexcel.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bfd02a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(variable_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779257f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    Name|Age|\n",
      "+--------+---+\n",
      "| Krishna|450|\n",
      "|Sudanshu| 30|\n",
      "|    Mike| 33|\n",
      "|  Vedant|100|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variable_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6537435",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variable_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583bddd",
   "metadata": {},
   "source": [
    "#**DataFrame Session started**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39685b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame Session started \n",
    "read_data=SparkSession.builder.appName('DataFrame').getOrCreate()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cde66a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#by default data is read as \"strings\"\n",
    "read_data.read.option('header','true').csv('DataFrames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04b474e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to infer datatype as it is we use \",inferSchema=True\"\n",
    "dataframe_var=read_data.read.option('header','true').csv('DataFrames.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0133a284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_var.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bbbb824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataframe_var.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d89a6586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krishna', Age=450, Experience=10),\n",
       " Row(Name='Sudanshu', Age=30, Experience=8),\n",
       " Row(Name='Mike', Age=33, Experience=4),\n",
       " Row(Name='Vedant', Age=100, Experience=2)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_var.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915984d",
   "metadata": {},
   "source": [
    "#Adding columns in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d801bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_var=dataframe_var.withColumn('Experience_after_2yrs',dataframe_var['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a747df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+---------------------+\n",
      "|    Name|Age|Experience|Experience_after_2yrs|\n",
      "+--------+---+----------+---------------------+\n",
      "| Krishna|450|        10|                   12|\n",
      "|Sudanshu| 30|         8|                   10|\n",
      "|    Mike| 33|         4|                    6|\n",
      "|  Vedant|100|         2|                    4|\n",
      "+--------+---+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_var.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40634c",
   "metadata": {},
   "source": [
    "#Dropping a column in pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffbc51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_var=dataframe_var.drop('Experience_after_2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40c6eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|    Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "| Krishna|450|        10|\n",
      "|Sudanshu| 30|         8|\n",
      "|    Mike| 33|         4|\n",
      "|  Vedant|100|         2|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_var.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e059ec",
   "metadata": {},
   "source": [
    "#Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3f4a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "326c30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "65fcb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_csv_data=spark.read.csv('HandlingMissingVals.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1f91dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "| Krishna| 450|        10| 30000|\n",
      "|Sudanshu|  30|         8| 25000|\n",
      "|    Mike|  33|         4| 20000|\n",
      "|  Vedant| 100|         2| 20000|\n",
      "| shubham|  22|         2| 90000|\n",
      "|  mahesh|null|      null| 40000|\n",
      "|    null|  34|        10| 20000|\n",
      "|    null|  28|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_csv_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5917e4",
   "metadata": {},
   "source": [
    "#to drop all the rows having any number of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view_csv_data.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d8c7f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "| Krishna| 450|        10| 30000|\n",
      "|Sudanshu|  30|         8| 25000|\n",
      "|    Mike|  33|         4| 20000|\n",
      "|  Vedant| 100|         2| 20000|\n",
      "| shubham|  22|         2| 90000|\n",
      "|  mahesh|null|      null| 40000|\n",
      "|    null|  34|        10| 20000|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop(how= \"any\") which is default, \n",
    "#thresh means atleast 2 non null values should be present\n",
    "view_csv_data.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e60ebd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "| Krishna|450|        10| 30000|\n",
      "|Sudanshu| 30|         8| 25000|\n",
      "|    Mike| 33|         4| 20000|\n",
      "|  Vedant|100|         2| 20000|\n",
      "| shubham| 22|         2| 90000|\n",
      "|    null| 34|        10| 20000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if ther is any row having Experience column as null it will\n",
    "# be droped\n",
    "view_csv_data.na.drop(how='any',subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532afee9",
   "metadata": {},
   "source": [
    "#Filling the Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0a076d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "| Krishna| 450|        10| 30000|\n",
      "|Sudanshu|  30|         8| 25000|\n",
      "|    Mike|  33|         4| 20000|\n",
      "|  Vedant| 100|         2| 20000|\n",
      "| shubham|  22|         2| 90000|\n",
      "|  mahesh|null|      null| 40000|\n",
      "|    null|  34|        10| 20000|\n",
      "|    null|  28|      null|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_csv_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56a6b31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|    Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "| Krishna| 450|        10| 30000|\n",
      "|Sudanshu|  30|         8| 25000|\n",
      "|    Mike|  33|         4| 20000|\n",
      "|  Vedant| 100|         2| 20000|\n",
      "| shubham|  22|         2| 90000|\n",
      "|  mahesh|null|         0| 40000|\n",
      "|    null|  34|        10| 20000|\n",
      "|    null|  28|         0|  null|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NOTE: the data type of the replace value should be same as that of column datatype\n",
    "view_csv_data.na.fill(value=0,subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b103e3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    Name|Age|Experience|Salary|\n",
      "+--------+---+----------+------+\n",
      "| Krishna|450|        10| 30000|\n",
      "|Sudanshu| 30|         8| 25000|\n",
      "|    Mike| 33|         4| 20000|\n",
      "|  Vedant|100|         2| 20000|\n",
      "| shubham| 22|         2| 90000|\n",
      "|  mahesh|  0|      null| 40000|\n",
      "|    null| 34|        10| 20000|\n",
      "|    null| 28|      null|  null|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_csv_data.na.fill(value=0,subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "030f5a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| Age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|     Krishna| 450|        10| 30000|\n",
      "|    Sudanshu|  30|         8| 25000|\n",
      "|        Mike|  33|         4| 20000|\n",
      "|      Vedant| 100|         2| 20000|\n",
      "|     shubham|  22|         2| 90000|\n",
      "|      mahesh|null|      null| 40000|\n",
      "|MissingValue|  34|        10| 20000|\n",
      "|MissingValue|  28|      null|  null|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_csv_data.na.fill(value='MissingValue',subset='Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257ceba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
